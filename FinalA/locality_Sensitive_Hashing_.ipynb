{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATo0T7SCoVo3",
        "outputId": "b2a723bf-1ef4-4737-cdda-b0daeef8689d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import hashlib\n",
        "import itertools\n",
        "import random\n",
        "import sys\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.sparse import csr_matrix, csc_matrix, coo_matrix, lil_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import hashlib\n",
        "import itertools\n",
        "import random\n",
        "import sys\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.sparse import csr_matrix, csc_matrix, coo_matrix, lil_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Movie_1  Movie_2  Movie_3  Movie_4  Movie_5\n",
            "User_1        4        4        4        4        1\n",
            "User_2        2        5        2        4        1\n",
            "User_3        3        4        5        5        2\n",
            "User_4        1        2        4        4        3\n",
            "User_5        3        1        5        5        2\n"
          ]
        }
      ],
      "source": [
        "n_users = 5    # Number of users\n",
        "n_movies = 5   # Number of movies\n",
        "\n",
        "# Generate a user-movie rating matrix with random ratings between 1 and 5\n",
        "ratings = np.random.randint(1, 6, size=(n_users, n_movies))\n",
        "\n",
        "# Create a DataFrame for better visualization\n",
        "user_ids = [f\"User_{i+1}\" for i in range(n_users)]\n",
        "movie_ids = [f\"Movie_{j+1}\" for j in range(n_movies)]\n",
        "user_movie = pd.DataFrame(ratings, index=user_ids, columns=movie_ids)\n",
        "print(user_movie)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdzKFILy53GN",
        "outputId": "c96bebc6-dfdb-4143-fca9-12a05201a7b6"
      },
      "outputs": [
        {
          "ename": "InvalidIndexError",
          "evalue": "(slice(None, None, None), 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[0;32m~/miniconda3/envs/IDL/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mindex.pyx:173\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), 1)' is an invalid key",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 146\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hs:\n\u001b[1;32m    145\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bs:\n\u001b[0;32m--> 146\u001b[0m       candidate_pair, signature_matrix, sparse_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mcandidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_movie\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m       \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(candidate_pair))\n\u001b[1;32m    148\u001b[0m       labels\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, b=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mcandidates\u001b[0;34m(user_movie, h, b, seed)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcandidates\u001b[39m(user_movie, h\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, b\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# sparse matrix\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     movies_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mmax(\u001b[43muser_movie\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m      5\u001b[0m     users_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mmax(user_movie[:, \u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m      7\u001b[0m     sparse_matrix \u001b[38;5;241m=\u001b[39m coo_matrix((np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(user_movie)), (user_movie[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, user_movie[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)))\n",
            "File \u001b[0;32m~/miniconda3/envs/IDL/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m~/miniconda3/envs/IDL/lib/python3.10/site-packages/pandas/core/indexes/base.py:3817\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3817\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3818\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/IDL/lib/python3.10/site-packages/pandas/core/indexes/base.py:6059\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   6055\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   6056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   6057\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   6058\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 6059\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
            "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 1)"
          ]
        }
      ],
      "source": [
        "\n",
        "def candidates(user_movie, h=200, b=20, seed=1):\n",
        "\n",
        "    # sparse matrix\n",
        "    movies_num = int(np.max(user_movie[:, 1]))\n",
        "    users_num = int(np.max(user_movie[:, 0]))\n",
        "\n",
        "    sparse_matrix = coo_matrix((np.ones(len(user_movie)), (user_movie[:, 1] - 1, user_movie[:, 0] - 1)))\n",
        "    sparse_matrix = sparse_matrix.tocsc()\n",
        "\n",
        "    # signature matrix\n",
        "    signature_matrix = np.full((h, users_num), np.inf)\n",
        "    np.random.seed(seed)\n",
        "    hash_permutations = np.array([np.random.permutation(movies_num) for _ in range(h)])\n",
        "    rows, cols = sparse_matrix.nonzero()\n",
        "    for i in range(h):\n",
        "        permuted_rows = hash_permutations[i, rows]\n",
        "        np.minimum.at(signature_matrix[i], cols, permuted_rows + 1)\n",
        "\n",
        "    # print(signature_matrix)\n",
        "    r = h // b\n",
        "\n",
        "    # hash into bucket\n",
        "    bucket_dict_list = []\n",
        "    for b_ in range(b):\n",
        "      bucket_dict = dict()\n",
        "      for u in range(users_num):\n",
        "        start = r*b_\n",
        "        end = r*(b_+1)\n",
        "        data = str(tuple(signature_matrix[start:end, u])).encode('utf-8')\n",
        "        # bucket_id = hash(data)\n",
        "        bucket_id = hashlib.sha256(data).hexdigest()\n",
        "        if bucket_id not in bucket_dict.keys():\n",
        "          bucket_dict[bucket_id] = [u+1]\n",
        "        else:\n",
        "          bucket_dict[bucket_id].append(u+1)\n",
        "      bucket_dict_list.append(bucket_dict)\n",
        "\n",
        "\n",
        "    # candidate pairs\n",
        "    candidate_pairs = set()\n",
        "    for bucket_dict in bucket_dict_list:\n",
        "      for bucket_id, bucket in bucket_dict.items():\n",
        "        if len(bucket) > 1 and len(bucket) < 20:\n",
        "          candidate_pairs.update(itertools.combinations(bucket, 2))\n",
        "\n",
        "    candidate_pairs = list(candidate_pairs)\n",
        "    return candidate_pairs, signature_matrix, sparse_matrix\n",
        "\n",
        "\n",
        "def calculate_similarity(candidate_pairs):\n",
        "    pair_counts = []\n",
        "    user_rated_movies = {user: user_movie[user_movie[:, 0] == user][:,1] for user in np.unique(user_movie[:, 0])}\n",
        "    for candidates in candidate_pairs:\n",
        "      pair_count = 0\n",
        "      for candidate in candidates:\n",
        "          C1 = user_rated_movies[candidate[0]]\n",
        "          C2 = user_rated_movies[candidate[1]]\n",
        "          jsim = len(np.intersect1d(C1, C2)) / len(np.union1d(C1, C2))\n",
        "          if jsim > 0.5:\n",
        "              pair_count += 1\n",
        "      pair_counts.append(pair_count)\n",
        "    return pair_counts\n",
        "\n",
        "\n",
        "\n",
        "def calculate_jaccard_similarity(sparse_matrix, candidate_pairs):\n",
        "    pair_counts = []\n",
        "    for i, candidates in enumerate(candidate_pairs):\n",
        "        pair_count = 0\n",
        "        candidates = np.array(candidates)\n",
        "        user1_indices = candidates[:, 0] - 1\n",
        "        user2_indices = candidates[:, 1] - 1\n",
        "\n",
        "        for user1, user2 in zip(user1_indices, user2_indices):\n",
        "            C1 = sparse_matrix[:, user1]\n",
        "            C2 = sparse_matrix[:, user2]\n",
        "            intersection = C1.minimum(C2).sum()\n",
        "            union = C1.maximum(C2).sum()\n",
        "            jsim = intersection / union if union > 0 else 0\n",
        "\n",
        "\n",
        "            if jsim > 0.5:\n",
        "                pair_count += 1\n",
        "        pair_counts.append(pair_count)\n",
        "    return pair_counts\n",
        "\n",
        "\n",
        "def calculate_signature_similarity(signature_matrices, candidate_pairs):\n",
        "    pair_counts = []\n",
        "    for signature_matrix, candidates in zip(signature_matrices, candidate_pairs):\n",
        "        pair_count = 0\n",
        "\n",
        "        candidates = np.array(candidates)\n",
        "        user1_indices = candidates[:, 0] - 1\n",
        "        user2_indices = candidates[:, 1] - 1\n",
        "\n",
        "        C1 = signature_matrix[:, user1_indices]\n",
        "        C2 = signature_matrix[:, user2_indices]\n",
        "\n",
        "        agree_matrix = C1 == C2\n",
        "        agree_counts = np.sum(agree_matrix, axis=0)\n",
        "        total_rows = signature_matrix.shape[0]\n",
        "\n",
        "        jsim_values = agree_counts / total_rows\n",
        "\n",
        "        for jsim in jsim_values:\n",
        "            if jsim > 0.5:\n",
        "                pair_count += 1\n",
        "        pair_counts.append(pair_count)\n",
        "    return pair_counts\n",
        "\n",
        "\n",
        "'''def calculate_signature_similarity(signature_matrices, candidate_pairs):\n",
        "    pair_counts = []\n",
        "    for signature_matrix, candidates in zip(signature_matrices, candidate_pairs):\n",
        "        pair_count = 0\n",
        "        for candidate in candidates:\n",
        "            user1, user2 = candidate\n",
        "            C1 = signature_matrix[:, user1 - 1]\n",
        "            C2 = signature_matrix[:, user2 - 1]\n",
        "            agree_rows = np.sum(C1 == C2)\n",
        "            total_rows = signature_matrix.shape[0]\n",
        "            jsim = agree_rows/total_rows\n",
        "            if jsim > 0.5:\n",
        "\n",
        "                pair_count += 1\n",
        "        pair_counts.append(pair_count)\n",
        "    return pair_counts'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # candidate b\n",
        "    bs = [20] #, 30, 40, 50\n",
        "    hs = [100] # 80,\n",
        "    num_candidates = []\n",
        "    candidate_pairs = []\n",
        "    signature_matrices = []\n",
        "    labels = []\n",
        "\n",
        "    # random seed\n",
        "    # randomseed = int(sys.argv[1])\n",
        "    for h in hs:\n",
        "      for b in bs:\n",
        "          candidate_pair, signature_matrix, sparse_matrix = candidates(user_movie, h=h, b=b)\n",
        "          print(len(candidate_pair))\n",
        "          labels.append(f\"h={h}, b={b}\")\n",
        "          num_candidates.append(len(candidate_pair))\n",
        "          candidate_pairs.append(candidate_pair)\n",
        "          signature_matrices.append(signature_matrix)\n",
        "\n",
        "\n",
        "    '''fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    ax.bar(labels, num_candidates, align='center')\n",
        "    plt.xlabel('(h, b)')\n",
        "    plt.ylabel('Number of Candidates')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "'''\n",
        "\n",
        "\n",
        "    '''pair_count = calculate_similarity(candidate_pairs)\n",
        "    print(pair_count)'''\n",
        "\n",
        "    pair_count = calculate_jaccard_similarity(sparse_matrix, candidate_pairs)\n",
        "    print(pair_count)\n",
        "\n",
        "    '''pair_count = calculate_signature_similarity(signature_matrices, candidate_pairs)\n",
        "    print(pair_count)'''\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "IDL",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
